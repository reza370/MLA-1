{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT NUMBER 1\n",
    "In this assignment, you will solve a problem, i.e., Chaky company makes some car but he has\n",
    "difficulty setting the price for the car. Please make a simple web-based car price prediction system.\n",
    "Note: You are ENCOURAGED to work with your friends, but DISCOURAGED to blindly copy\n",
    "other’s work. Both parties will be given 0.\n",
    "Note: Comments should be provided sufficiently so we know you understand. Failure to do so can\n",
    "raise suspicion of possible copying/plagiarism.\n",
    "Note: You will be graded upon (1) documentation, (2) experiment, (3) implementation.\n",
    "Note: This is a two-weeks assignment, but start early.\n",
    "Deliverables: The GitHub link containing the jupyter notebook, a README.md of the github, and\n",
    "the folder of your web application called ‘app’.\n",
    "\n",
    "***************************************************************************************************\n",
    "\n",
    "Task 1. Preparing the datasets\n",
    "Download the Car Price dataset from Google classroom. \n",
    "Perform loading, \n",
    "EDA, \n",
    "preprocessing,\n",
    "model selection, · · · , inference.\n",
    "\n",
    "There are some important coding considerations:\n",
    "• For the feature owner, map First owner to 1, ..., Test Drive Car to 5\n",
    "• For the feature fuel, remove all rows with CNG and LPG because CNG and LPG use a different\n",
    "mileage system i.e., km/kg which is different from kmfeaturepl for Diesel and Petrol \n",
    "• For the feature mileage, remove “kmpl” and convert the column to numerical type (e.g., float). Hint: use\n",
    "df.mileage.str.split\n",
    "• For the feature engine, remove “CC” and convert the column to numerical type (e.g., float)\n",
    "• Do the same for max power\n",
    "• For the feature brand, take only the first word and remove the rest\n",
    "• Drop the feature torque, simply because Chaky’s company does not understand well about it \n",
    "• You will found out that Test Drive Cars are ridiculously expensive. Since we do not want to involve\n",
    "  this, we will simply delete all samples related to it.\n",
    "• Since selling price is a big number, it can cause your prediction to be very unstable. One trick is\n",
    "  to first transform the label using log transform, i.e., y = np.log(df['selling_price'])\n",
    "• During inference/testing, you have to transform your predicted y backed before comparing with y\n",
    "test, i.e., pred_y = np.exp(pred_y)\n",
    "\n",
    "**********************************************************************************************\n",
    "\n",
    "Task 2. Report - In the end of the notebook, please write a 2-3 paragraphs summary deeply\n",
    "discussing and analysing the results. Possible points of discussion:\n",
    "• Which features are important? Which are not? Why?\n",
    "• Which algorithm performs well? Which does not? Why? (here, you haven’t learned about any\n",
    "algorithms yet, but you can search online a bit and start building an intuition)\n",
    "\n",
    "**********************************************************************************************\n",
    "\n",
    "Task 3. Deployment - Develop a web-based application that contains the model. Here you will be\n",
    "tasked to self-study how to deploy the model into production. Here are some guidelines: Here you\n",
    "have multiple options. Those who are veteran web developer may prefer their own web app stack\n",
    "which is welcomed. For those who are new to this realm, you may consider a simpler/one-stop\n",
    "solution rather than learning the traditional/flexible approach.\n",
    "The goal of this task is to expose/deploy our model for public use via the web interface. The main\n",
    "scenario is the following:\n",
    "1) Users enter the domain on their browser. They land on your page.\n",
    "2) (optional) Users may need to navigate to a prediction page.\n",
    "3) Users read the instruction given on the page that instructs them on how the prediction\n",
    "works. 4) Users find the input form, put in the appropriate data, and click submit.\n",
    "5) Note that if users do not have information on certain field, you have to allow users to skip that\n",
    "field. In that case, we recommend you to fill the missing field with imputation technique you\n",
    "have learned in the class.\n",
    "6) A moment later (depending on your model and hardware performance), the result is returned\n",
    "and printed below the form.\n",
    "Deploying aside, the app should work on the local environment (your machine) first. I would suggest\n",
    "you use ‘Dash’ by ‘Plotly’ https://dash.plotly.com/ as a one-stop solution. Spend time studying the\n",
    "‘Quick Start’ tutorial on the site and also ‘Dash Fundamental’. They are essential for you to know how\n",
    "‘Dash’ works.\n",
    "The deliverable for the app would be, in GitHub, you have a folder ‘app’ with ‘.Dockerfile’, ‘docker\n",
    "compose.yaml’ files, and ‘code’ folder.\n",
    "Bootstrap: I know Dockerizing the app could be difficult for newcomers, you will get confused when\n",
    "searching for stuff online, especially, when you just trust ChatGPT to give you the right answer. So, for\n",
    "those who want to postpone the process of learning “Docker”, here is the Dockerized Dash project\n",
    "link. Don’t worry, you will eventually need to do this yourself in this shortcoming weeks. You can not\n",
    "escape this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_cars=pd.read_csv('Cars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the created data set: (number of samples (rows), number of variables (columns), column names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coding feature \"owner\": First Owner --> 1, Second Owner --> 2, Third owner --> 3, Fourth & Above Owner --> 4, Test Drive Car --> 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_coding = {\n",
    "    'First Owner': 1,\n",
    "    'Second Owner': 2,\n",
    "    'Third Owner': 3,\n",
    "    'Fourth & Above Owner': 4,\n",
    "    'Test Drive Car': 5\n",
    "}\n",
    "\n",
    "df_cars['owner'] = df_cars['owner'].map(owner_coding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows with fuel values 'CNG' or 'LPG':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = df_cars[df_cars['fuel'].isin(['Petrol', 'Diesel'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing “kmpl” for the feature mileage, and convert the column to numerical type (e.g., float). \n",
    "Removing “CC” for the feature engine,  and convert the column to numerical type (e.g., float)\n",
    "Removing “bph” for the feature engine,  and convert the column to numerical type (e.g., float)\n",
    "for max_power, there is a single value that is equal to 'bph', to get a correct result the value is changed to ' bph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.mileage = df_cars.mileage.str.split(expand=True)[0].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.engine = df_cars.engine.str.split(expand=True)[0].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.loc[df_cars['max_power'] == 'bph', 'max_power'] = ' bph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.max_power = df_cars.max_power.str.split(expand=True)[0].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking only the first word and removing the rest For the feature brand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.name=df_cars.name.str.split(expand=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Droping the feature torque:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = df_cars.drop(columns=['torque'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting all samples related to \"Test Drive Cars == 5\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = df_cars[df_cars['owner'] != 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming selling price by log transform function since selling price is a big number. y = np.log(df['selling_price']):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_cars['selling_price'] = np.log(df_cars['selling_price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is likely that the producing year of cars to be important for predicting the car's price, a new variable age is created to use as a feuture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "df_cars['car_age'] = int(now.strftime(\"%Y\")) - df_cars['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final check for loaded car data set structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "np.__version__, pd.__version__, sns.__version__, matplotlib.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_num = df_cars.describe(include=['float', 'int'])\n",
    "desc_str = df_cars.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horizental Count Plot (Bar plot) is created for each categorical features to explore their distribution and any unusual values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df_cars, y = 'name', color = 'Grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df_cars, y = 'fuel', color = 'Grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df_cars, y = 'seller_type', color = 'Grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df_cars, y = 'transmission', color = 'Grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df_cars, y = 'owner', color = 'Grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df_cars, y = 'seats', color = 'grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution Plot (Histogram) is useful to see how continues label and features are distributed. also we can find any deviation from a normal distribution e.g. outliers, unusual observation, skewness or kurtosis can be found from these plots, furthermore we can use these plots to find the appropriate measure for imputing missing data. however outlier detection and imputation will be done in the preprecessing phase.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df_cars, x = 'selling_price', color = 'Green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df_cars, x = 'km_driven', color = 'Green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df_cars, x = 'mileage', color = 'Green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df_cars, x = 'engine', color = 'Green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df_cars, x = 'max_power', color = 'Green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data = df_cars, x = 'car_age', color = 'Green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plot is very usefull for exploring attributes distribution as well as outliers. creating this plot for the continues attributes by the values of categorical feuthers enables us to compare distribution in subcategory samples. In this regression case, boxplots of the label by categorical feathurs are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = df_cars[\"selling_price\"]);\n",
    "plt.ylabel(\"Selling Price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot( y = df_cars[\"selling_price\"], x = df_cars[\"fuel\"]);\n",
    "plt.ylabel(\"Selling Price\")\n",
    "plt.xlabel(\"Fuel Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot( y = df_cars[\"selling_price\"], x = df_cars[\"seller_type\"]);\n",
    "plt.ylabel(\"Selling Price\")\n",
    "plt.xlabel(\"Seller Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot( y = df_cars[\"selling_price\"], x = df_cars[\"transmission\"]);\n",
    "plt.ylabel(\"Selling Price\")\n",
    "plt.xlabel(\"Transmission Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot( y = df_cars[\"selling_price\"], x = df_cars[\"owner\"]);\n",
    "plt.ylabel(\"Selling Price\")\n",
    "plt.xlabel(\"First Owner:1, Second Owner:2, Third Owner:3, Fourth & Above Owner:4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot is useful to see how the label and continues features are related. we can find none, linear, or nonlinear correlation (not causation) \n",
    "between label and features and this is useful in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_cars[['selling_price', 'km_driven', 'mileage', 'engine', 'max_power', 'car_age']], diag_kind='kde', corner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['engine'], y = df_cars['selling_price'], hue=df_cars['seller_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['engine'], y = df_cars['selling_price'], hue=df_cars['transmission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['engine'], y = df_cars['selling_price'], hue=df_cars['fuel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['engine'], y = df_cars['selling_price'], hue=df_cars['owner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['max_power'], y = df_cars['selling_price'], hue=df_cars['seller_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['max_power'], y = df_cars['selling_price'], hue=df_cars['transmission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['max_power'], y = df_cars['selling_price'], hue=df_cars['fuel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['max_power'], y = df_cars['selling_price'], hue=df_cars['owner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['car_age'], y = df_cars['selling_price'], hue=df_cars['seller_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['car_age'], y = df_cars['selling_price'], hue=df_cars['transmission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['car_age'], y = df_cars['selling_price'], hue=df_cars['fuel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = df_cars['car_age'], y = df_cars['selling_price'], hue=df_cars['owner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Matrix\n",
    "correlation matrix is useful to find strong factors predicting the selling price. however we found some facts about this in scatter plots. It's also for checking whether certain features are too correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.loc[(df_cars['transmission'] == 'Manual','transmission_code')] = 0\n",
    "df_cars.loc[(df_cars['transmission'] == 'Automatic', 'transmission_code')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.loc[(df_cars['fuel'] == 'Petrol','fuel_code')] = 0\n",
    "df_cars.loc[(df_cars['fuel'] == 'Diesel', 'fuel_code')] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to consider correlation between features fuel, transmission, and seller_type, we encode them into 0 & 1 features (for seller type: one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.loc[(df_cars['seller_type'] == 'Individual', 'individual_seller')] = 1\n",
    "df_cars.loc[(df_cars['seller_type'] == 'Dealer', 'individual_seller')] = 0\n",
    "df_cars.loc[(df_cars['seller_type'] == 'Trustmark Dealer', 'individual_seller')] = 0\n",
    "df_cars.loc[(df_cars['seller_type'] == 'Dealer', 'Dealer_seller')] = 1\n",
    "df_cars.loc[(df_cars['seller_type'] == 'Individual', 'Dealer_seller')] = 0\n",
    "df_cars.loc[(df_cars['seller_type'] == 'Trustmark Dealer', 'Dealer_seller')] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.heatmap(df_cars[['selling_price', 'km_driven', 'mileage', 'engine', 'max_power', 'seats', 'owner',\\\n",
    "    'car_age', 'fuel_code', 'transmission_code', 'individual_seller', 'Dealer_seller' ]].corr(), annot=True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.heatmap(df_cars[['selling_price', 'km_driven', 'mileage', 'engine', 'max_power', 'seats', 'owner',\\\n",
    "    'car_age', 'fuel_code', 'transmission_code', 'individual_seller', 'Dealer_seller' ]].corr(method='spearman'), annot=True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppscore as pps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before using pps, let's drop country and year\n",
    "df_cars_copy = df_cars.copy()\n",
    "df_cars_copy.drop(['name', 'year', 'fuel', 'seller_type', 'transmission'], axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this needs some minor preprocessing because seaborn.heatmap unfortunately does not accept tidy data\n",
    "matrix_df_cars = pps.matrix(df_cars_copy)[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.heatmap(matrix_df_cars, vmin=0, vmax=1, cmap=\"Reds\", linewidths=0.5, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature selection\n",
    "after exploring data, calculating pearson and spearman corerelation, and predictive power scores, features max_power,, mileage, engine, car_age, and transmission_code seem more strong for prediction of label selling_price. because feature engine are strongly correlated with max_power (r = 0.7) so we can leave it out from our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_cars[['max_power', 'mileage', 'car_age']]\n",
    "y = df_cars['selling_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test set creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, X_train.shape, y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = X_train['max_power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = X_train['mileage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['max_power', 'mileage']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to impute null values for features max_power and mileage their distribution and outliers considered. max_power distribution is skewed to the right and there is slightly significance difference between mean and median so for this feature, median is used as a null filling measure. Feature mileage distribution has no outlier and mean is used for imputing null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['max_power'].fillna(X_train['max_power'].median(), inplace=True)\n",
    "X_train['mileage'].fillna(X_train['mileage'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['max_power'].fillna(X_train['max_power'].median(), inplace=True)\n",
    "X_test['mileage'].fillna(X_train['mileage'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is no need to scaling because we don't have any feature with big values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "yhat = lr.predict(X_test)\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_test, yhat))\n",
    "print('R2: ', r2_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression  #we are using regression models\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Libraries for model evaluation\n",
    "\n",
    "# models that we will be using, put them in a list\n",
    "algorithms = [LinearRegression(), SVR(), KNeighborsRegressor(), DecisionTreeRegressor(random_state = 0), \n",
    "              RandomForestRegressor(n_estimators = 100, random_state = 0)]\n",
    "\n",
    "# The names of the models\n",
    "algorithm_names = [\"Linear Regression\", \"SVR\", \"KNeighbors Regressor\", \"Decision-Tree Regressor\", \"Random-Forest Regressor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "#lists for keeping mse\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "\n",
    "#defining splits\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for i, model in enumerate(algorithms):\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    print(f\"{algorithm_names[i]} - Score: {scores}; Mean: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'bootstrap': [True], 'max_depth': [5, 10, None],\n",
    "              'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 1)\n",
    "\n",
    "grid = GridSearchCV(estimator = rf, \n",
    "                    param_grid = param_grid, \n",
    "                    cv = kfold, \n",
    "                    n_jobs = -1, \n",
    "                    return_train_score=True, \n",
    "                    refit=True,\n",
    "                    scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit your grid_search\n",
    "grid.fit(X_train, y_train);  #fit means start looping all the possible parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find your grid_search's best score\n",
    "best_mse = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mse  # ignore the minus because it's neg_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = grid.predict(X_test)\n",
    "mean_squared_error(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stored in this variable\n",
    "#note that grid here is random forest\n",
    "rf = grid.best_estimator_\n",
    "\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot\n",
    "plt.barh(X.columns, rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmm...let's sort first\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "plt.barh(X.columns[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_importance = permutation_importance(rf, X_test, y_test)\n",
    "\n",
    "#let's plot\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "plt.barh(X.columns[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap provides plot\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", feature_names = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model/Car_selling_price.model'\n",
    "pickle.dump(grid, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars[['max_power', 'mileage', 'car_age']].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([[70, 15, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_car_price = np.exp(loaded_model.predict(sample))\n",
    "predicted_car_price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
